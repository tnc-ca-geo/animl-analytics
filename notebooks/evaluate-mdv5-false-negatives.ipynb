{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Megadetector v5(a) false negatives\n",
    "\n",
    "The purpose of this Notebooks is to test the detection rate of Megadetector v5(a) on real data from Animl and evaluate (a) whether adjusting the confidence threshold can reduce false negatives, and (b) what the detection rate looks like at the sequence/burst level compared to the individual image level.\n",
    "\n",
    "The first part of the notebook pulls a block of image records down from MongoDB within a date range and uses their timestamps to group them into bursts/sequences. \n",
    "\n",
    "The second part of the notebook queries MongoDB for all* image records that contain false negatives for a given class/species within that same date range, downloads those actual image files into memory, submits them to the SageMaker-hosted MDv5 endpoint, and filters the results at a lower confidence threshold to determine whether lowering the confidence threshold would have reduced false negatives.\n",
    "\n",
    "Finally, we evaluate the other images in the bursts of the remaining false negative records to check whether there were successful detections elsewhere in their respective sequences. \n",
    "\n",
    "\\* there are some caveats to be aware of with this query. See the \"Find false negative section below\" for more info.\n",
    "\n",
    "\n",
    "*NOTE: This notebook is intended to be run locally, and assumes the following:*\n",
    "- you are currently running a virtual env with Python 3.9\n",
    "- you have configured the awscli with an account called \"animl\" with the requisite permissions to read from S3 and invoke Sagemaker endpoints\n",
    "- you have a MongoDB Atlas URL/connection string with read permissions stored in a .env file\n",
    "\n",
    "*See README for assistence with any of the above*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MongoDB Atlas Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "MONGODB_URL = os.getenv('MONGODB_URL')\n",
    "\n",
    "db_client = MongoClient(MONGODB_URL)\n",
    "db = db_client['animl-prod']\n",
    "images = db['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, time, json\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "os.environ['AWS_PROFILE'] = 'animl'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "region = sess.region_name\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "img_bucket = 'animl-images-serving-prod'\n",
    "class_map = { 1: 'animal', 2: 'person', 3: 'vehicle' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check status of SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "endpoint_name = 'megadetectorv5-torchserve-serverless-prod'\n",
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(f'Status: {status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "project = 'sci_biosecurity'\n",
    "start = datetime(2022, 7, 16)\n",
    "end = datetime(2022, 11, 1)\n",
    "category = 'rodent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_image_records(q):\n",
    "    img_count = images.count_documents(q)\n",
    "    print(f'found {img_count} image records')\n",
    "    img_rcrds = list(images.find(q))\n",
    "    return img_rcrds\n",
    "\n",
    "def download_image_files(img_rcrds):\n",
    "    print('Downloading image files to memory...')\n",
    "    ret = []\n",
    "    for rec in img_rcrds:\n",
    "        key = f\"original/{rec['_id']}-original.jpg\"\n",
    "        img = boto3.client('s3').get_object(Bucket=img_bucket, Key=key)['Body'].read()\n",
    "        ret.append({ 'name': rec['_id'], 'data': img })\n",
    "    print(f'Downloaded {len(ret)} images to memory')\n",
    "    return ret\n",
    "\n",
    "def detect_objects(imgs):\n",
    "    print('Submitting images to endpoint for object detection...')\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    ret = []\n",
    "    for i in range(len(imgs)):\n",
    "        response = client.invoke_endpoint(\n",
    "            EndpointName = endpoint_name,\n",
    "            ContentType = 'application/x-image',\n",
    "            Body = imgs[i]['data']\n",
    "        )\n",
    "        response = json.loads(response['Body'].read())\n",
    "        ret.append({ 'name': imgs[i]['name'], 'objects': response })\n",
    "        if i % 5 == 0:\n",
    "            print(f'successfully detected objects in image {i + 1}/{len(imgs)}')\n",
    "    return ret\n",
    "\n",
    "def filter_dets(imgs, conf, classes):\n",
    "    print(f'filtering detections below confidence threshold {conf}')\n",
    "    def func(obj): \n",
    "        if obj['confidence'] < conf or obj['class'] not in classes:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    for img in imgs:\n",
    "        img['filtered_objects'] = list(filter(func, img['objects']))\n",
    "    return imgs\n",
    "\n",
    "def draw_bounding_box_on_image(image,ymin,xmin,ymax,xmax,classification):\n",
    "    color_map = { 1: 'red', 2: 'blue', 3: 'yellow' }\n",
    "    color = color_map.get(classification)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "               (right, top), (left, top)], width=4, fill=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for sequence grouping\n",
    "\n",
    "import uuid\n",
    "\n",
    "def stage_for_grouping(delta_index, index_array):\n",
    "    for i in [delta_index, delta_index + 1]:\n",
    "        if i not in index_array: \n",
    "            index_array.append(i)\n",
    "\n",
    "def group_as_sequence(dep_img_indexes, dep_df, images_df):\n",
    "    # use indices to get image ids from deployments DataFrame\n",
    "    img_ids = dep_df.iloc[dep_img_indexes]\n",
    "    img_ids = img_ids['_id'].tolist()\n",
    "    # find the corresponding images records in the images DataFrame\n",
    "    # and assign them the same burstId\n",
    "    burstId = uuid.uuid4()\n",
    "    images_df.loc[images_df['_id'].isin(img_ids), 'burstId'] = burstId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate image records with burst Ids\n",
    " - pull all image records (for a specific project & within date range) into a DataFrame\n",
    " - split out by deployment\n",
    " - sort each deployment's image records chronologically\n",
    " - create array of time deltas between each image\n",
    " - iterate deltas, if the delta is <= some fixed delta limit (say, 2 seconds), treat them as being in the same burst\n",
    " - as a sanity check, print out a list of all the images in chronological order along side an \"image is in burst\" or \"image is not in burst\" evaluation... the images IN bursts should be clustered together chronologically (assuming that setting could get turned on/off)\n",
    " - other interesting stats would be: avg number of images in bursts, count of outliers (e.g. bursts w/ 4+ images or 2 images)\n",
    "\n",
    "End goal is be able to map an image to a burst, and get the rest of the images in that burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = { \n",
    "  'projectId': project,\n",
    "  'dateAdded': { '$gt': start, '$lt': end }\n",
    "}\n",
    "\n",
    "# read image records into DataFrame\n",
    "raw_img_rcrds = get_image_records(query)\n",
    "images_df = pd.DataFrame(raw_img_rcrds)\n",
    "\n",
    "# add burstId column, parse dateTimeOriginal values as datetime64, sort chronologically\n",
    "images_df['burstId'] = None\n",
    "images_df['dateTimeOriginal'] = images_df['dateTimeOriginal'].apply(pd.to_datetime)\n",
    "images_df.sort_values('dateTimeOriginal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out all possible dep_ids\n",
    "deploymentIds = np.unique(images_df['deploymentId'].values)\n",
    "print(f'identified {len(deploymentIds)} deployment(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over deployments and group images into sequences\n",
    "max_delta = 2 # seconds\n",
    "\n",
    "for deploymentId in deploymentIds:\n",
    "    # create deployment DataFrame\n",
    "    dep_df = images_df.loc[images_df['deploymentId'] == deploymentId]\n",
    "\n",
    "    # get time deltas (as timedelta64's)\n",
    "    deltas = np.diff(dep_df['dateTimeOriginal']).astype('float64')\n",
    "    \n",
    "    # iterate over the deltas and group images by sequence\n",
    "    img_indexes_to_sequence = []\n",
    "    for i, delta in enumerate(deltas):\n",
    "        if delta/1e9 <= max_delta:\n",
    "            # the two images are part of same sequence\n",
    "            stage_for_grouping(i, img_indexes_to_sequence)\n",
    "        else:\n",
    "            # this is a gap between sequences\n",
    "            if len(img_indexes_to_sequence) > 0:\n",
    "                group_as_sequence(img_indexes_to_sequence, dep_df, images_df)\n",
    "                img_indexes_to_sequence = []\n",
    "\n",
    "        if i == len(deltas) - 1:\n",
    "            # we've reached the last delta in the array, \n",
    "            # so group the last staged sequence if there is one\n",
    "            if len(img_indexes_to_sequence) > 0:\n",
    "                group_as_sequence(img_indexes_to_sequence, dep_df, images_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional - save each deployment to a CSV (helpful for QA/QCing the burst Ids)\n",
    "for deploymentId in deploymentIds:\n",
    "    dep_df = images_df.loc[images_df['deploymentId'] == deploymentId]\n",
    "    dep_df.to_csv(f'imgs_with_burst_ids-{deploymentId}.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MongoDB query\n",
    "This query is an attempt to Id Megadetector v5a false negatives. For more info: https://docs.google.com/spreadsheets/d/1xaMsICF-e97Ndgm8A9hkrxNRQkJofPQSGOgO9ML8wHU/edit#gid=0\n",
    "\n",
    "A few caveats to this approach:\n",
    "- ideally we would measure label counts and false negatives at the object-level, but for now this is using images as a proxy (i.e., \"Validated label count\" does not mean the number of validated labels, it means the number of IMAGES that have at least one object with that particular label validated). We could correct for this & count up actual objects, but I'd have to write scripts, rather than DB queries, to do that. *This will result in a slight undercount.*\n",
    "- the query below looks for all images for which MDv5 had predicted there was nothing in it (we give those an \"empty\" label), but then a user invalidated that empty label and added their own object to the image manually. This doesn't account for situations in which MDv5 correctly guessed that there was an object *somewhere else* in the image (thus it wasn't given an \"empty\" label), but it didn't correctly guess all of the objects in the image (it missed others). *This will result in a slight undercount.*\n",
    "- because we're querying image records, the known label filtering bug (https://github.com/tnc-ca-geo/animl-api/issues/43) will slightly skew results. *This will result in a slight overcount*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "  'projectId': project,\n",
    "  'dateAdded': { '$gt': start, '$lt': end },\n",
    "  'objects': {\n",
    "      '$elemMatch': {\n",
    "        '$and': [\n",
    "          {'locked': True},\n",
    "          {'labels': {\n",
    "              '$elemMatch': {\n",
    "                  '$and': [\n",
    "                      {'type': 'ml'},\n",
    "                      {'mlModel': 'megadetector'},\n",
    "                      {'validation.validated': False},\n",
    "                      {'category':'empty'}\n",
    "                  ]\n",
    "              }\n",
    "          }}\n",
    "        ]\n",
    "      }\n",
    "  },\n",
    "  'objects.labels': {\n",
    "      '$elemMatch': {\n",
    "        '$and': [\n",
    "            {'type': 'manual'},\n",
    "            {'validation.validated': True},\n",
    "            {'category': category}\n",
    "        ]\n",
    "      }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read image records & image files into memory, submit to MDv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rcrds = get_image_records(query)\n",
    "imgs = download_image_files(img_rcrds)\n",
    "img_detections = detect_objects(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter detections below confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # class schema we use is 1 for animal, 2 for person, 3 for vehicle\n",
    "conf = 0.1\n",
    "classes_to_include = [1,2]  # suppress vehicles\n",
    "\n",
    "imgs_with_filtered_detections = filter_dets(\n",
    "  img_detections,\n",
    "  conf,\n",
    "  classes_to_include\n",
    ")\n",
    "\n",
    "count = 0 \n",
    "imgs_with_dets_above_threshold = []\n",
    "for i, img in enumerate(imgs_with_filtered_detections):\n",
    "    if len(img['filtered_objects']) > 0:\n",
    "        imgs_with_dets_above_threshold.append(img['name'])\n",
    "    for obj in img['filtered_objects']:\n",
    "        print(f\"{i} --- {img['name']} --- {obj['class']} --- {obj['confidence']}\")\n",
    "        count = count + 1\n",
    "\n",
    "print(f'found {count} objects with detections above {conf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check false negatives\n",
    "for true positivies in their respective bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_has_true_positive(img):\n",
    "    # return true if image has an object w/ a megadetector label AND\n",
    "    # a validated label of our desired class\n",
    "    ret = False\n",
    "    for obj in img.objects:\n",
    "        has_md_label = False\n",
    "        has_validated_label = False\n",
    "        for lbl in obj[\"labels\"]:\n",
    "            if (lbl[\"type\"] == \"ml\" and \n",
    "                lbl[\"mlModel\"] == \"megadetector\"):\n",
    "                has_md_label = True\n",
    "            if (lbl[\"category\"] == category and \n",
    "                \"validation\" in lbl and \n",
    "                lbl[\"validation\"][\"validated\"] == True):\n",
    "                has_validated_label = True\n",
    "        if has_md_label and has_validated_label:\n",
    "            ret = True\n",
    "    return ret\n",
    "\n",
    "def burst_has_true_positive(img_rcrd):\n",
    "    # print(f'checking img {img_rcrd[\"_id\"]}')\n",
    "\n",
    "    # find img's burstId\n",
    "    burstId = images_df.loc[images_df['_id'] == img_rcrd['_id'], 'burstId'].tolist()\n",
    "    # print(f'burstId: {burstId[0]}')\n",
    "\n",
    "    # find rest of images in burst, filter out this img\n",
    "    imgs_in_burst = images_df.loc[images_df['burstId'] == burstId[0]]\n",
    "    # print(f'images in burst: \\n{imgs_in_burst[\"_id\"]}')\n",
    "\n",
    "    # for each remaining image, check for true positive\n",
    "    ret = False\n",
    "    for row in imgs_in_burst.itertuples():\n",
    "        has_true_positive = img_has_true_positive(row)\n",
    "        if has_true_positive:\n",
    "            ret = True\n",
    "    return ret\n",
    "\n",
    "def remove_true_positives(img):\n",
    "    return img['_id'] not in imgs_with_dets_above_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the bursts of all remaining false negatives\n",
    "# (i.e., those that would have still been missed even with a lower conf. threshold)\n",
    "# for true positives\n",
    "\n",
    "imgs_to_check_bursts = list(filter(remove_true_positives, img_rcrds))\n",
    "detection_found_in_burst_count = 0\n",
    "for img in imgs_to_check_bursts:\n",
    "    if burst_has_true_positive(img):\n",
    "        detection_found_in_burst_count = detection_found_in_burst_count + 1\n",
    "\n",
    "print(\n",
    "    f'found {detection_found_in_burst_count} true positives in the bursts ' + \n",
    "    f'associated with {len(imgs_to_check_bursts)} images that had false negatives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot-check individual images & objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 3\n",
    "img_to_draw = imgs_with_filtered_detections[img_index]\n",
    "image = Image.open(BytesIO(imgs[img_index]['data']))\n",
    "\n",
    "print(f\"{img_index} --- {img_to_draw['name']}\")\n",
    "for obj in img_to_draw['filtered_objects']:\n",
    "    print(f\"object --- class: {obj['class']} ({class_map[obj['class']]}), confidence: {obj['confidence']}\")\n",
    "    draw_bounding_box_on_image(image, obj['y1'], obj['x1'], obj['y2'], obj['x2'], obj['class'])\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a32203625ae4601d0f31d6c2e53060237b1f8755ca09d3f623f698a4ce3645da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
